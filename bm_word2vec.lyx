#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
BM
\end_layout

\begin_layout Standard
visible vector
\begin_inset Formula $v\in\{0,1\}^{m}$
\end_inset


\end_layout

\begin_layout Standard
hidden vector 
\begin_inset Formula $h\in\{0,1\}^{n}$
\end_inset


\end_layout

\begin_layout Standard
weights matrix 
\begin_inset Formula $W\in R^{(m+n)\times(m+n)}$
\end_inset

,where 
\begin_inset Formula $W_{ij}=W_{ji}$
\end_inset

 and 
\begin_inset Formula $W_{ii}=0$
\end_inset

.
\end_layout

\begin_layout Standard
bias vector 
\begin_inset Formula $b\in R^{(m+n)}$
\end_inset


\end_layout

\begin_layout Standard
energy function
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E(x)=-\frac{1}{2}xWx^{T}-xb^{T}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $x=\{v,h\}$
\end_inset

.
 And 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
p(x)=\frac{\exp\{-E(x)\}}{\sum_{x}\exp\{-E(x)\}}
\end{equation}

\end_inset


\end_layout

\begin_layout Section
Word Embedding
\end_layout

\begin_layout Standard
\begin_inset Formula $m$
\end_inset

 is the meaning of a word ;
\begin_inset Formula $w$
\end_inset

 is the word; 
\begin_inset Formula $p(m|w)$
\end_inset

 is the meaning distribution that a word follows.
 Then we can state the mutual information between meaning and words:
\begin_inset Formula 
\begin{equation}
I(M;W)=H(M)-H(M|W)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Although 
\begin_inset Formula $H(M)$
\end_inset

 is unknown, it should be fixed.
 That means we can only focus on the second part of above objective function.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
H(M|W)=\sum_{w}p(w)H(M|w)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $p(w)$
\end_inset

 is the known word frequency.
 Minimizing 
\begin_inset Formula $H(M|W)$
\end_inset

 is our goal.
 
\end_layout

\begin_layout Standard
How to represent the meaning of one word is a difficult thing in a model.
 Intuitively, the meaning of any word can be interpreted by other words.
 We can assume that the distribution 
\begin_inset Formula $p(M|w)$
\end_inset

 is a distribution of words.
 What is the distribution 
\begin_inset Formula $p(M|w)$
\end_inset

? We only have corpus at hand.
 How can we compute 
\begin_inset Formula $p(M|w)$
\end_inset

 by existing corpus?
\end_layout

\begin_layout Standard
We use 
\begin_inset Formula $v_{i}$
\end_inset

 representing a word 
\begin_inset Formula $w_{i}$
\end_inset

 and a Boltzmann machine representing distribution 
\begin_inset Formula $p(M|w)$
\end_inset

, where 
\begin_inset Formula $v_{i}\in\{0,1\}^{n}$
\end_inset

 .
 That is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f:\ w_{i}\rightarrow v_{i}\in\{0,1\}^{n}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
and this Boltzmann machine is consisted by three parts: the first input,
 the second input and the hidden nodes.
 In this model, distribution 
\begin_inset Formula $p(M|w)$
\end_inset

 is represented by 
\begin_inset Formula $p(v_{j}|v_{i})$
\end_inset

, where
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
p(v_{j}|v_{i})=\sum_{h}p(v_{j},h|v_{i})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We train this model as follows:
\end_layout

\begin_layout Enumerate
Initially, we randomly generate the bijective function between 
\begin_inset Formula $w_{i}$
\end_inset

 and 
\begin_inset Formula $\{0,1\}^{n}$
\end_inset

 sequences.
\end_layout

\begin_layout Enumerate
We generate data set 
\begin_inset Formula $X$
\end_inset

, where 
\begin_inset Formula $X_{k}=\{f(w_{i}),\ f(w_{j})\}$
\end_inset

, both 
\begin_inset Formula $w_{i}$
\end_inset

 and 
\begin_inset Formula $w_{j}$
\end_inset

 appear in the same sentences.
\end_layout

\begin_layout Enumerate
In each epoch, we train Boltzmann machine using our method(Gibbs sampling
 + persistent contrastive divergence).
\end_layout

\begin_layout Enumerate
After each epoch, we adjust the bijective function through
\begin_inset Formula 
\begin{equation}
f^{*}=\arg\min_{f}D(p(w_{i})\|p(f(w_{i})))
\end{equation}

\end_inset

 where 
\begin_inset Formula $p(w_{i})$
\end_inset

 is the word frequency, 
\begin_inset Formula $p(f(w_{i}))$
\end_inset

 is the posibility of 
\begin_inset Formula $f(w_{i})$
\end_inset

 in the Boltzmann machine.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename bm_word.png

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
A simple example.
 This Boltzmann machine is consisted by three parts: the first input 
\begin_inset Formula $v_{i}$
\end_inset

, the second part 
\begin_inset Formula $v_{j}$
\end_inset

 and the hidden nodes 
\begin_inset Formula $h$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_body
\end_document
