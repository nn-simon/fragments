Batch Normalization导读 张俊林
Deep Reinforcement Learning 基础知识（DQN方面）(songrotek)
Human-level control through deep reinforcement learning
Paper Reading 3:Continuous control with Deep Reinforcement Learning(songrotek)
解密Google Deepmind AlphaGo围棋算法：真人工智能来自于哪里？(songrotek)
了解点OpenAI及深度学习研究前沿(songrotek)
深度学习计算模型中“门函数（Gating Function）”的作用(张俊林)
深度学习与自然语言处理之五：从RNN到LSTM(张俊林)
以Attention Model为例谈谈两种研究创新模式(张俊林)
自然语言处理中的Attention Model：是什么及为什么(张俊林)
李飞飞ICML2016

Bayesian Optimization
Javad Azimi Fall 2010 http://web.engr.oregonstate.edu/~azimi/ 

Entropy methods
www.stat.yale.edu/~pollard/Books/Asymptopia/old-Entropy.pdf

A Brief Introduction to Kolmogorov Complexity.pdf
Achieving the Gaussian Rate-Distortion Function by prediction.pdf
A Diversity-Promoting Objective Function for Neural Conversation Models.pdf
A Mathematical Theory of Learning.pdf
Analysis of commercial and free and open source solvers for linear optimation problems.pdf
A Neural Probabilistic Language Model.pdf
An Information Theoretic Perspective of the sparse coding.pdf
An Introduction to CRF for relational learning.pdf
ant colony optimization.pdf
A RATE-DISTORTION FRAMEWORK FOR SUPERVISED LEARNING.pdf
Artificial Convolution Neural Network for Medical Image.pdf
A Sparse-Response Deep Belief Network Based on Rate distortion theory.pdf
Basic Text Process.pdf
Bayesian Classification with gaussian process.pdf
bayesian-optimization.pptx
Bounded Rational Decision-Making in Feedforward Neural Networks.pdf
Challenges in Representation Learning A report on three machine learning contests.pdf
Compressive Sampling and Lossy Compression.pdf
Compressive Sensing.pdf
DEEP COMPRESSION(ICLR).pdf
Deep Face Recognition.pdf
Deep Learning Face Representation from Predicting 10,000 Classes.pdf
Deep Neural networks in machine translation_an overview.pdf
Discriminative Gaussian Process Latent models for calssification.pdf
Distances and affinities between measures.pdf
Emotion Recognition in the Wild via Convolutional Neural Networks and Mapped Binary Patterns.pdf
Entropy methods.pdf
Factorization of Latent Variables in Distributional Semantic Models.pdf
Fast-RCNN.pdf
Feed Forward Rate Distortion Function and Markov Sources.pdf
Fully Convolutional Networks for Semantic Segmentation.pdf
Gaussian Processes for Machine Learning.pdf
Generating Text with Recurrent Neural Networks.pdf
Generation and Comprehension of Unambiguous Object Descriptions.pdf
Hierarchical Clustering Based on Mutual Information.pdf
Introduction to Compressed sensing.pdf
Joint Word Representation Learning using a Corpus and a Semantic Lexicon.pdf
Kolmogorov Complexity.pdf
Machine Translation with LSTMs.pdf
Maximum Mutual Information Estimation with Unlabeled Data for phonetic classfication.PDF
Maximum mutual information regularized classification.pdf
Multi-Task Bayesian Optimization.pdf
Mutual Information and Diverse Decoding Improve Neural Machine translation.pdf
NEURAL MACHINE TRANSLATION by jointly learning to align and translate.pdf
neural word embeddings as implicit matrix factorization.pdf
On competitive prediction and its relation to rate-distortion theory.pdf
On the Properties of Neural Machine Translation_ Encoder–Decoder approach.pdf
ON THE RATE-DISTORTION PERFORMANCE OF COMPRESSED SENSING.pdf
Opportunistic Scheduling with Limited Channel State Information A Rate Distortion Approach.pdf
Perceptron Mistake Bounds.pdf
Random Matrices.pdf
random_report.pdf
senna-v3.0.tgz
Sequence to Sequence Learning with neural network.pdf
Shannon Information and Kolmogorov Complexity.pdf
Shannon Theoretic Limits on Noisy compressive sampling.pdf
Size and form in efficient transportation networks(nature).pdf
Structured Compressed Sensing_ from theory to application.pdf
Structured Recurrent Temporal Restricted Boltzmann Machines.pdf
sxzm.pdf
The Recurrent Temporal Restricted Boltzmann machine.pdf
thirty_years.txt
UFLDL(andrew ng).pdf
Unsupervised Feature Learning and Deep Learning_A Review and New Perspectives.pdf
VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION.pdf
Wide Residual Networks.pdf
幂律分布研究简史.pdf
激荡三十年-吴晓波.txt
神经网络的函数逼近理论.pdf
随机过程（Sheldon M.Ross 著）.pdf
作者：刘皮皮
链接：http://www.zhihu.com/question/31181823/answer/50954547
来源：知乎
著作权归作者所有，转载请联系作者获得授权。
Stacked convolutional auto-encoders for hierarchical feature extraction, Jonathan Masci, Ueli Meier, Dan Cire?san, and J¨urgen Schmidhuber, 2011
In visual object recognition, CNNs [1,3,4,14,26] often excel. Unlike patch based methods [19] they preserve the input’s neighborhood relations and spatial locality in their latent higher-level feature representations. While the common fully connected deep architectures do not scale well to realistic-sized high-dimensional images in terms of computational complexity, CNNs do, since the number of free parameters describing their shared weights does not depend on the input dimensionality.
Artificial convolution neural network for medical image pattern recognition
https://onedrive.live.com/redir?resid=DB4CF9BA40D4F042!4626&authkey=!AFfCWlXvZdm2X_Y&ithint=folder%2c
An Information Theoretic Perspective of the Sparse Coding
Ian Goodfellow, Yoshua Bengio and Aaron Courville <deep learning>

